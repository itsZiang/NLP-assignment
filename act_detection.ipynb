{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:23:50.435919Z","iopub.execute_input":"2024-12-30T21:23:50.436190Z","iopub.status.idle":"2024-12-30T21:23:54.965610Z","shell.execute_reply.started":"2024-12-30T21:23:50.436168Z","shell.execute_reply":"2024-12-30T21:23:54.964247Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/itsZiang/data.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:23:54.966961Z","iopub.execute_input":"2024-12-30T21:23:54.967320Z","iopub.status.idle":"2024-12-30T21:23:56.714648Z","shell.execute_reply.started":"2024-12-30T21:23:54.967287Z","shell.execute_reply":"2024-12-30T21:23:56.713802Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'data'...\nremote: Enumerating objects: 11, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 11 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (11/11), 3.46 MiB | 4.74 MiB/s, done.\nResolving deltas: 100% (2/2), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport shutil\nimport sys\nimport tqdm.notebook as tq\nfrom collections import defaultdict\n\nimport torch\nimport torch.nn as nn\n\nfrom transformers import BertTokenizer, BertModel\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:23:56.716257Z","iopub.execute_input":"2024-12-30T21:23:56.716504Z","iopub.status.idle":"2024-12-30T21:24:02.003642Z","shell.execute_reply.started":"2024-12-30T21:23:56.716468Z","shell.execute_reply":"2024-12-30T21:24:02.002914Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\n\n# Function to load the list of unique acts from the text file\ndef load_acts_from_txt(file_path):\n    with open(file_path, 'r') as file:\n        acts = file.read().splitlines()\n    return acts\n\n# Function to convert a list of acts to a one-hot encoded vector\ndef convert_to_one_hot(acts, all_acts):\n    one_hot_vector = [0] * len(all_acts)\n    for act in acts:\n        if act in all_acts:\n            one_hot_vector[all_acts.index(act)] = 1\n    return one_hot_vector\n\n# Function to load and process the JSON files into DataFrames\ndef load_json_data(json_path, all_acts):\n    with open(json_path, 'r') as f:\n        json_data = json.load(f)\n\n    data = []\n    for entry in json_data:\n        utterance = entry[\"utterance\"]\n        acts = entry[\"acts\"]\n        one_hot_encoded_acts = convert_to_one_hot(acts, all_acts)\n        # Concatenate the utterance with the one-hot encoded vector\n        data.append([utterance] + one_hot_encoded_acts)\n\n    # Create a DataFrame from the processed data\n    column_names = [\"utterance\"] + all_acts\n    df = pd.DataFrame(data, columns=column_names)\n    return df\n\n# Paths to your JSON files and the acts.txt file\ntrain_json_path = '/kaggle/working/data/data_act_detection_train.json'\ntest_json_path = '/kaggle/working/data/data_act_detection_test.json'\ndev_json_path = '/kaggle/working/data/data_act_detection_dev.json'\nacts_txt_path = '/kaggle/working/data/acts_name.txt'\n\n# Load the unique acts from the acts.txt file\nall_acts = load_acts_from_txt(acts_txt_path)\n\n# Load and process the JSON files into separate DataFrames\ndf_train = load_json_data(train_json_path, all_acts)\ndf_test = load_json_data(test_json_path, all_acts)\ndf_valid = load_json_data(dev_json_path, all_acts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:02.004853Z","iopub.execute_input":"2024-12-30T21:24:02.005239Z","iopub.status.idle":"2024-12-30T21:24:04.004094Z","shell.execute_reply.started":"2024-12-30T21:24:02.005208Z","shell.execute_reply":"2024-12-30T21:24:04.003438Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(f\"Train: {df_train.shape}, Test: {df_test.shape}, Valid: {df_valid.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:04.004837Z","iopub.execute_input":"2024-12-30T21:24:04.005049Z","iopub.status.idle":"2024-12-30T21:24:04.009633Z","shell.execute_reply.started":"2024-12-30T21:24:04.005031Z","shell.execute_reply":"2024-12-30T21:24:04.008770Z"}},"outputs":[{"name":"stdout","text":"Train: (113552, 37), Test: (14744, 37), Valid: (14748, 37)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\ndf_valid.head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:04.010538Z","iopub.execute_input":"2024-12-30T21:24:04.010838Z","iopub.status.idle":"2024-12-30T21:24:04.041450Z","shell.execute_reply.started":"2024-12-30T21:24:04.010807Z","shell.execute_reply":"2024-12-30T21:24:04.040786Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                           utterance  Booking-NoBook  \\\n0  I'm looking for a local place to dine in the c...               0   \n\n   Police-Request  Attraction-Inform  Booking-Inform  general-greet  \\\n0               0                  0               0              0   \n\n   Hospital-Inform  Hotel-Select  general-thank  Train-Request  \\\n0                0             0              0              0   \n\n   Train-OfferBooked  Hotel-Recommend  Train-OfferBook  Restaurant-NoOffer  \\\n0                  0                0                0                   0   \n\n   Hospital-Request  Booking-Request  Attraction-Select  Restaurant-Recommend  \\\n0                 0                0                  0                     0   \n\n   general-reqmore  Attraction-Recommend  Taxi-Inform  Taxi-Request  \\\n0                0                     0            0             0   \n\n   general-welcome  general-bye  Train-Inform  Hotel-NoOffer  Hotel-Inform  \\\n0                0            0             0              0             0   \n\n   Train-NoOffer  Restaurant-Select  Hotel-Request  Attraction-NoOffer  \\\n0              0                  0              0                   0   \n\n   Police-Inform  Attraction-Request  Restaurant-Inform  Booking-Book  \\\n0              0                   0                  1             0   \n\n   Restaurant-Request  Train-Select  \n0                   0             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance</th>\n      <th>Booking-NoBook</th>\n      <th>Police-Request</th>\n      <th>Attraction-Inform</th>\n      <th>Booking-Inform</th>\n      <th>general-greet</th>\n      <th>Hospital-Inform</th>\n      <th>Hotel-Select</th>\n      <th>general-thank</th>\n      <th>Train-Request</th>\n      <th>Train-OfferBooked</th>\n      <th>Hotel-Recommend</th>\n      <th>Train-OfferBook</th>\n      <th>Restaurant-NoOffer</th>\n      <th>Hospital-Request</th>\n      <th>Booking-Request</th>\n      <th>Attraction-Select</th>\n      <th>Restaurant-Recommend</th>\n      <th>general-reqmore</th>\n      <th>Attraction-Recommend</th>\n      <th>Taxi-Inform</th>\n      <th>Taxi-Request</th>\n      <th>general-welcome</th>\n      <th>general-bye</th>\n      <th>Train-Inform</th>\n      <th>Hotel-NoOffer</th>\n      <th>Hotel-Inform</th>\n      <th>Train-NoOffer</th>\n      <th>Restaurant-Select</th>\n      <th>Hotel-Request</th>\n      <th>Attraction-NoOffer</th>\n      <th>Police-Inform</th>\n      <th>Attraction-Request</th>\n      <th>Restaurant-Inform</th>\n      <th>Booking-Book</th>\n      <th>Restaurant-Request</th>\n      <th>Train-Select</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I'm looking for a local place to dine in the c...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Hyperparameters\nMAX_LEN = 64\nTRAIN_BATCH_SIZE = 64\nVALID_BATCH_SIZE = 32\nTEST_BATCH_SIZE = 32\nEPOCHS = 6\nLEARNING_RATE = 1e-05\nTHRESHOLD = 0.5 # threshold for the sigmoid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:04.042298Z","iopub.execute_input":"2024-12-30T21:24:04.042515Z","iopub.status.idle":"2024-12-30T21:24:04.046199Z","shell.execute_reply.started":"2024-12-30T21:24:04.042470Z","shell.execute_reply":"2024-12-30T21:24:04.045220Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:04.047065Z","iopub.execute_input":"2024-12-30T21:24:04.047296Z","iopub.status.idle":"2024-12-30T21:24:05.227722Z","shell.execute_reply.started":"2024-12-30T21:24:04.047278Z","shell.execute_reply":"2024-12-30T21:24:05.226875Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5f1ec3242c4ada9c2b305fb55d25f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72fdca86dca748d89311d081258d080d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d21a6a67876c436bb4e5fc4bb2a4afd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a79545aa16d432db4b60476490fb052"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, df, tokenizer, max_len, target_list):\n        self.tokenizer = tokenizer\n        self.df = df\n        self.utterance = list(df['utterance'])\n        self.targets = self.df[target_list].values\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.utterance)\n\n    def __getitem__(self, index):\n        utterance = str(self.utterance[index])\n        utterance = \" \".join(utterance.split())\n        inputs = self.tokenizer.encode_plus(\n            utterance,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': inputs['input_ids'].flatten(),\n            'attention_mask': inputs['attention_mask'].flatten(),\n            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n            'targets': torch.FloatTensor(self.targets[index]),\n            'utterance': utterance\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:05.229918Z","iopub.execute_input":"2024-12-30T21:24:05.230133Z","iopub.status.idle":"2024-12-30T21:24:05.235821Z","shell.execute_reply.started":"2024-12-30T21:24:05.230114Z","shell.execute_reply":"2024-12-30T21:24:05.234897Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"target_list = all_acts\ntarget_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:05.237700Z","iopub.execute_input":"2024-12-30T21:24:05.237924Z","iopub.status.idle":"2024-12-30T21:24:05.253560Z","shell.execute_reply.started":"2024-12-30T21:24:05.237905Z","shell.execute_reply":"2024-12-30T21:24:05.252885Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['Booking-NoBook',\n 'Police-Request',\n 'Attraction-Inform',\n 'Booking-Inform',\n 'general-greet',\n 'Hospital-Inform',\n 'Hotel-Select',\n 'general-thank',\n 'Train-Request',\n 'Train-OfferBooked',\n 'Hotel-Recommend',\n 'Train-OfferBook',\n 'Restaurant-NoOffer',\n 'Hospital-Request',\n 'Booking-Request',\n 'Attraction-Select',\n 'Restaurant-Recommend',\n 'general-reqmore',\n 'Attraction-Recommend',\n 'Taxi-Inform',\n 'Taxi-Request',\n 'general-welcome',\n 'general-bye',\n 'Train-Inform',\n 'Hotel-NoOffer',\n 'Hotel-Inform',\n 'Train-NoOffer',\n 'Restaurant-Select',\n 'Hotel-Request',\n 'Attraction-NoOffer',\n 'Police-Inform',\n 'Attraction-Request',\n 'Restaurant-Inform',\n 'Booking-Book',\n 'Restaurant-Request',\n 'Train-Select']"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\nvalid_dataset = CustomDataset(df_valid, tokenizer, MAX_LEN, target_list)\ntest_dataset = CustomDataset(df_test, tokenizer, MAX_LEN, target_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:05.254318Z","iopub.execute_input":"2024-12-30T21:24:05.254668Z","iopub.status.idle":"2024-12-30T21:24:05.305258Z","shell.execute_reply.started":"2024-12-30T21:24:05.254634Z","shell.execute_reply":"2024-12-30T21:24:05.304532Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_data_loader = torch.utils.data.DataLoader(train_dataset,\n    batch_size=TRAIN_BATCH_SIZE,\n    shuffle=True,\n    num_workers=4\n)\n\nval_data_loader = torch.utils.data.DataLoader(valid_dataset,\n    batch_size=VALID_BATCH_SIZE,\n    shuffle=False,\n    num_workers=4\n)\n\ntest_data_loader = torch.utils.data.DataLoader(test_dataset,\n    batch_size=TEST_BATCH_SIZE,\n    shuffle=False,\n    num_workers=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:05.306054Z","iopub.execute_input":"2024-12-30T21:24:05.306341Z","iopub.status.idle":"2024-12-30T21:24:05.310889Z","shell.execute_reply.started":"2024-12-30T21:24:05.306312Z","shell.execute_reply":"2024-12-30T21:24:05.310081Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.linear = torch.nn.Linear(768, 36)\n\n    def forward(self, input_ids, attn_mask, token_type_ids):\n        output = self.bert_model(\n            input_ids,\n            attention_mask=attn_mask,\n            token_type_ids=token_type_ids\n        )\n        output_dropout = self.dropout(output.pooler_output)\n        output = self.linear(output_dropout)\n        return output\n\nmodel = BERTClass()\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:05.311686Z","iopub.execute_input":"2024-12-30T21:24:05.311892Z","iopub.status.idle":"2024-12-30T21:24:08.110281Z","shell.execute_reply.started":"2024-12-30T21:24:05.311874Z","shell.execute_reply":"2024-12-30T21:24:08.109550Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a7368acde264ef98b0fd5d5ad25948b"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (bert_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=768, out_features=36, bias=True)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.111053Z","iopub.execute_input":"2024-12-30T21:24:08.111268Z","iopub.status.idle":"2024-12-30T21:24:08.114599Z","shell.execute_reply.started":"2024-12-30T21:24:08.111252Z","shell.execute_reply":"2024-12-30T21:24:08.113952Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr = 1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.115430Z","iopub.execute_input":"2024-12-30T21:24:08.115680Z","iopub.status.idle":"2024-12-30T21:24:08.576159Z","shell.execute_reply.started":"2024-12-30T21:24:08.115661Z","shell.execute_reply":"2024-12-30T21:24:08.575286Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Training of the model for one epoch\ndef train_model(training_loader, model, optimizer):\n\n    losses = []\n    correct_predictions = 0\n    num_samples = 0\n    # set model to training mode (activate droput, batch norm)\n    model.train()\n    # initialize the progress bar\n    loop = tq.tqdm(enumerate(training_loader), total=len(training_loader),\n                      leave=True, colour='steelblue')\n    for batch_idx, data in loop:\n        ids = data['input_ids'].to(device, dtype = torch.long)\n        mask = data['attention_mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        # forward\n        outputs = model(ids, mask, token_type_ids) # (batch,predict)=(32,8)\n        loss = loss_fn(outputs, targets)\n        losses.append(loss.item())\n        # training accuracy, apply sigmoid, round (apply thresh 0.5)\n        outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n        targets = targets.cpu().detach().numpy()\n        correct_predictions += np.sum(outputs==targets)\n        num_samples += targets.size   # total number of elements in the 2D array\n\n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        # grad descent step\n        optimizer.step()\n\n        # Update progress bar\n        #loop.set_description(f\"\")\n        #loop.set_postfix(batch_loss=loss)\n\n    # returning: trained model, model accuracy, mean loss\n    return model, float(correct_predictions)/num_samples, np.mean(losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.577111Z","iopub.execute_input":"2024-12-30T21:24:08.577628Z","iopub.status.idle":"2024-12-30T21:24:08.584031Z","shell.execute_reply.started":"2024-12-30T21:24:08.577595Z","shell.execute_reply":"2024-12-30T21:24:08.583172Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def eval_model(validation_loader, model, optimizer):\n    losses = []\n    correct_predictions = 0\n    num_samples = 0\n    # set model to eval mode (turn off dropout, fix batch norm)\n    model.eval()\n\n    with torch.no_grad():\n        for batch_idx, data in enumerate(validation_loader, 0):\n            ids = data['input_ids'].to(device, dtype = torch.long)\n            mask = data['attention_mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n\n            loss = loss_fn(outputs, targets)\n            losses.append(loss.item())\n\n            # validation accuracy\n            # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n            outputs = torch.sigmoid(outputs).cpu().detach().numpy().round()\n            targets = targets.cpu().detach().numpy()\n            correct_predictions += np.sum(outputs==targets)\n            num_samples += targets.size   # total number of elements in the 2D array\n\n    return float(correct_predictions)/num_samples, np.mean(losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.584913Z","iopub.execute_input":"2024-12-30T21:24:08.585173Z","iopub.status.idle":"2024-12-30T21:24:08.603094Z","shell.execute_reply.started":"2024-12-30T21:24:08.585153Z","shell.execute_reply":"2024-12-30T21:24:08.602286Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"!mkdir /kaggle/working/output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.603918Z","iopub.execute_input":"2024-12-30T21:24:08.604187Z","iopub.status.idle":"2024-12-30T21:24:08.749750Z","shell.execute_reply.started":"2024-12-30T21:24:08.604160Z","shell.execute_reply":"2024-12-30T21:24:08.748644Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data_dir = \"/kaggle/working\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.750673Z","iopub.execute_input":"2024-12-30T21:24:08.750901Z","iopub.status.idle":"2024-12-30T21:24:08.754224Z","shell.execute_reply.started":"2024-12-30T21:24:08.750882Z","shell.execute_reply":"2024-12-30T21:24:08.753577Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"history = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(1, EPOCHS+1):\n    print(f'Epoch {epoch}/{EPOCHS}')\n    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n    val_acc, val_loss = eval_model(val_data_loader, model, optimizer)\n\n    print(f'train_loss={train_loss:.4f}, val_loss={val_loss:.4f} train_acc={train_acc:.4f}, val_acc={val_acc:.4f}')\n\n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    # save the best model\n    if val_acc > best_accuracy:\n        torch.save(model.state_dict(), os.path.join(data_dir,\"output\",\"best_model.bin\"))\n        best_accuracy = val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:24:08.755027Z","iopub.execute_input":"2024-12-30T21:24:08.755301Z","iopub.status.idle":"2024-12-30T22:27:58.508982Z","shell.execute_reply.started":"2024-12-30T21:24:08.755273Z","shell.execute_reply":"2024-12-30T22:27:58.507768Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e32deb7cd9ed4afba2498979a91cfa44"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.1331, val_loss=0.0577 train_acc=0.9658, val_acc=0.9849\nEpoch 2/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39f857ede4dd4f4fa48f79e6fe692950"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.0486, val_loss=0.0363 train_acc=0.9871, val_acc=0.9898\nEpoch 3/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c514e44e6e7a4d4ca3212d8c5c4d7ac6"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.0346, val_loss=0.0295 train_acc=0.9898, val_acc=0.9909\nEpoch 4/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeb2147d778641fb93ddb426f8f3fa29"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.0288, val_loss=0.0269 train_acc=0.9911, val_acc=0.9913\nEpoch 5/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0831756c2dfb4d1bbf2bd631daafeee6"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.0256, val_loss=0.0257 train_acc=0.9917, val_acc=0.9914\nEpoch 6/6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1775 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02de1d5dc9f44fd1b8a50fdc6d02206d"}},"metadata":{}},{"name":"stdout","text":"train_loss=0.0234, val_loss=0.0255 train_acc=0.9923, val_acc=0.9914\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Loading pretrained model (best model)\nmodel = BERTClass()\nmodel.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"best_model.bin\")))\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:27:58.510338Z","iopub.execute_input":"2024-12-30T22:27:58.510692Z","iopub.status.idle":"2024-12-30T22:27:59.775178Z","shell.execute_reply.started":"2024-12-30T22:27:58.510662Z","shell.execute_reply":"2024-12-30T22:27:59.774517Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-21-b5b868cf060b>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(os.path.join(data_dir,\"output\",\"best_model.bin\")))\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"test_acc, test_loss = eval_model(test_data_loader, model, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:27:59.775959Z","iopub.execute_input":"2024-12-30T22:27:59.776164Z","iopub.status.idle":"2024-12-30T22:28:25.121453Z","shell.execute_reply.started":"2024-12-30T22:27:59.776146Z","shell.execute_reply":"2024-12-30T22:28:25.120543Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"test_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:28:25.122555Z","iopub.execute_input":"2024-12-30T22:28:25.122855Z","iopub.status.idle":"2024-12-30T22:28:25.128180Z","shell.execute_reply.started":"2024-12-30T22:28:25.122833Z","shell.execute_reply":"2024-12-30T22:28:25.127301Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0.9913599505636944"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:28:25.129007Z","iopub.execute_input":"2024-12-30T22:28:25.129213Z","iopub.status.idle":"2024-12-30T22:28:25.785211Z","shell.execute_reply.started":"2024-12-30T22:28:25.129194Z","shell.execute_reply":"2024-12-30T22:28:25.784583Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def get_predictions(model, data_loader):\n    \"\"\"\n    Outputs:\n      predictions -\n    \"\"\"\n    model = model.eval()\n\n    utterances = []\n    predictions = []\n    prediction_probs = []\n    target_values = []\n\n    with torch.no_grad():\n      for data in data_loader:\n        utterance = data[\"utterance\"]\n        ids = data[\"input_ids\"].to(device, dtype = torch.long)\n        mask = data[\"attention_mask\"].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data[\"targets\"].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n        # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n        outputs = torch.sigmoid(outputs).detach().cpu()\n        # thresholding at 0.5\n        preds = outputs.round()\n        targets = targets.detach().cpu()\n\n        utterances.extend(utterance)\n        predictions.extend(preds)\n        prediction_probs.extend(outputs)\n        target_values.extend(targets)\n\n    predictions = torch.stack(predictions)\n    prediction_probs = torch.stack(prediction_probs)\n    target_values = torch.stack(target_values)\n\n    return utterances, predictions, prediction_probs, target_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:28:25.786003Z","iopub.execute_input":"2024-12-30T22:28:25.786413Z","iopub.status.idle":"2024-12-30T22:28:25.792602Z","shell.execute_reply.started":"2024-12-30T22:28:25.786391Z","shell.execute_reply":"2024-12-30T22:28:25.791752Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"utterances, predictions, prediction_probs, target_values = get_predictions(model, test_data_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:28:25.793383Z","iopub.execute_input":"2024-12-30T22:28:25.793686Z","iopub.status.idle":"2024-12-30T22:28:51.241773Z","shell.execute_reply.started":"2024-12-30T22:28:25.793656Z","shell.execute_reply":"2024-12-30T22:28:51.240629Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print(classification_report(target_values, predictions, target_names=target_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T22:28:51.245756Z","iopub.execute_input":"2024-12-30T22:28:51.245977Z","iopub.status.idle":"2024-12-30T22:28:51.303860Z","shell.execute_reply.started":"2024-12-30T22:28:51.245959Z","shell.execute_reply":"2024-12-30T22:28:51.302847Z"}},"outputs":[{"name":"stdout","text":"                      precision    recall  f1-score   support\n\n      Booking-NoBook       0.98      0.96      0.97       131\n      Police-Request       0.00      0.00      0.00         0\n   Attraction-Inform       0.89      0.91      0.90      1522\n      Booking-Inform       0.94      0.89      0.92       564\n       general-greet       1.00      0.01      0.02       240\n     Hospital-Inform       0.00      0.00      0.00         0\n        Hotel-Select       0.64      0.70      0.67        80\n       general-thank       0.98      0.94      0.96       940\n       Train-Request       0.90      0.90      0.90      1077\n   Train-OfferBooked       0.92      0.81      0.86       297\n     Hotel-Recommend       0.77      0.63      0.69       140\n     Train-OfferBook       0.92      0.85      0.88       380\n  Restaurant-NoOffer       0.91      0.91      0.91       111\n    Hospital-Request       0.00      0.00      0.00         0\n     Booking-Request       0.94      0.94      0.94       321\n   Attraction-Select       0.66      0.67      0.67        55\nRestaurant-Recommend       0.82      0.52      0.63       145\n     general-reqmore       0.87      0.93      0.90      1439\nAttraction-Recommend       0.71      0.72      0.72       148\n         Taxi-Inform       0.96      0.89      0.92       604\n        Taxi-Request       0.86      0.67      0.75       236\n     general-welcome       0.78      0.64      0.70       503\n         general-bye       0.90      0.98      0.94      1195\n        Train-Inform       0.94      0.96      0.95      2401\n       Hotel-NoOffer       0.85      0.79      0.82        67\n        Hotel-Inform       0.91      0.89      0.90      2156\n       Train-NoOffer       1.00      0.11      0.20         9\n   Restaurant-Select       0.75      0.70      0.73        87\n       Hotel-Request       0.84      0.64      0.73       577\n  Attraction-NoOffer       0.86      0.82      0.84        60\n       Police-Inform       0.50      0.67      0.57         3\n  Attraction-Request       0.85      0.67      0.75       676\n   Restaurant-Inform       0.91      0.89      0.90      2061\n        Booking-Book       0.91      0.94      0.93       537\n  Restaurant-Request       0.79      0.66      0.72       583\n        Train-Select       1.00      0.11      0.21        35\n\n           micro avg       0.90      0.86      0.88     19380\n           macro avg       0.79      0.68      0.70     19380\n        weighted avg       0.90      0.86      0.87     19380\n         samples avg       0.87      0.86      0.85     19380\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":27}]}